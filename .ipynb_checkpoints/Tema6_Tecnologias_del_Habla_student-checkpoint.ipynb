{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 6 Tecnologías del Habla\n",
    "\n",
    "\n",
    "### Rebeca Goya Esteban y Óscar Barquero Pérez\n",
    "\n",
    "update: 18 de octubre de 2018\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Licencia de Creative Commons\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />Este obra está bajo una <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">licencia de Creative Commons Reconocimiento-NoComercial-CompartirIgual 4.0 Internacional</a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Clasificadores Máquina\n",
    "\n",
    "En este notebook vamos a aplicar tres técnicas de aprendizaje máquina para resolver un problema de clasificación.\n",
    "\n",
    "**Descripción de los datos**: The iris data sets consists of 3 different types of irises’ (Setosa, Versicolour, and Virginica) petal and sepal length, stored in a 150x4 numpy.ndarray\n",
    "The rows being the samples and the columns being: Sepal Length, Sepal Width, Petal Length and Petal Width.\n",
    "\n",
    "\n",
    "En la siguiente celda se cargan los datos y se realiza una división de los mismos en un conjunto de entrenamiento y un conjunto de test. En *X_train* y *X_test* corresponden a carcterı́sticas de tres clases de flores, en total hay 150\n",
    "ejemplos. En *y_train* y *y_test* se encuentra la información de a qué clase\n",
    "pertenece cada una de las 150 flores (tres posibles clases).\n",
    "\n",
    "**¿Cuántas características se están utilizando para representar/describir a cada una de las flores?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n",
      "(105, 4)\n",
      "(45, 4)\n",
      "(105,)\n",
      "(45,)\n",
      "[0 0 1 2 1 2 2 0 0 0 2 2 1 2 1 0 0 1 0 2]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#imports\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "#load datasets and split into test and train\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "#X Características\n",
    "#Y Resultado / Tipo de flor\n",
    "X = iris.data  \n",
    "y = iris.target\n",
    "print(X)\n",
    "\n",
    "\n",
    "#Ver las dimensiones de las caracteristicas 4 veces 150 es decir\n",
    "#4 Caracteristicas \n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "#ver lo que hay dentro de y\n",
    "#print(y[50:70])\n",
    "\n",
    "#30% de test\n",
    "\n",
    "#split train test, se encarga de mezclar tambien\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "#Comprobar que esten mezclados\n",
    "print(y_train[0:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.1 Naive Bayes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar el Método de Clasificación de [Naïve Bayes GaussianNB](http://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes), donde hay dos asunciones básicas:\n",
    "\n",
    "* Asunción *naïve* de independencia condicional entre las características para una clase de la variable respuesta dada:\n",
    "\n",
    "$$P(x_1,\\ldots,x_d\\mid y_i) = \\prod_{k = 1}^{d}P(x_k\\mid y_i)$$\n",
    "\n",
    "* La verosimilitud de cada una de las características se asume Gaussiana:\n",
    "\n",
    "$$P(x_i \\mid y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_y}} \\exp\\left(-\\frac{(x_i - \\mu_y)^2}{2\\sigma^2_y}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento\n",
    "\n",
    "A continuación entrenamos el algoritmo, lo que implica calcular los parámetros $\\mu_y$ y $\\sigma_y$.\n",
    "\n",
    "* Utilice los datos de entrenamiento (*x_train_iris* y *y_train_iris*) y la función *GaussianNB.fit()* para estimar los parámetros de la pdf gaussiana de cada una de las 3 clases de flores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Creamos el modelo de NB\n",
    "\n",
    "model_NB = GaussianNB()\n",
    "\n",
    "#entrenamos\n",
    "\n",
    "model_NB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media de la gaussiana para cada clase:\n",
      " Columnas = Características \n",
      " Filas = Clases\n",
      "\n",
      "[[5.04864865 3.47027027 1.47297297 0.24324324]\n",
      " [5.946875   2.76875    4.23125    1.3125    ]\n",
      " [6.46944444 2.92777778 5.43611111 1.98333333]]\n"
     ]
    }
   ],
   "source": [
    "# Media y desviación estándar para las características de cada clase:\n",
    "\n",
    "print(\"Media de la gaussiana para cada clase:\\n Columnas = Características \\n Filas = Clases\\n\")\n",
    "#Accedemos al atributo mediante .____ atributo\n",
    "print(model_NB.theta_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desviación estándar de la gaussiana para cada clase:\n",
      " Columnas = Características \n",
      " Filas = Clases\n",
      "\n",
      "[[0.11006574 0.12857561 0.02575603 0.00948138]\n",
      " [0.24499024 0.11214844 0.17714844 0.03734375]\n",
      " [0.37989969 0.10756173 0.28619599 0.07416667]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Desviación estándar de la gaussiana para cada clase:\\n Columnas = Características \\n Filas = Clases\\n\")\n",
    "print(model_NB.sigma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "* Clasifique cada ejemplo (flor) de los datos de test (x test iris y y test iris) de acuerdo al esquema de clasificación Naive Bayes. Para ello, utilice *model_NB.predict(X_test)*\n",
    "* Calcule el error de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True False  True  True  True]\n",
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# Predecimos las muestras de test, utilizando los valores de la función estimados anteriorment en train\n",
    "\n",
    "y_hat_NB = model_NB.predict(X_test)\n",
    "\n",
    "#Utilizaremos y_test para comparar la estimacion con lo que realmente sabemos que hay\n",
    "\n",
    "#Calculamos el accuracy\n",
    "temp = y_hat_NB == y_test\n",
    "print(temp[0:20])\n",
    "\n",
    "acc = np.mean(y_hat_NB == y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.2 Ejemplo KNN con sklearn\n",
    "\n",
    "Vamos a utilizar el método de clasificación KNN https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    "**Pruebe diferentes valores para el parámetro K**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#K = 3 Numero de vecinos\n",
    "model_KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "#train the model \n",
    "model_KNN.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#predict outputs\n",
    "y_hat_KNN = model_KNN.predict(X_test)\n",
    "\n",
    "#accuracy\n",
    "\n",
    "acc = np.mean(y_hat_KNN == y_test)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2.3 redes neuronales\n",
    "\n",
    "Vamos a utilizar el método de clasificación redes neuronales https://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n",
    "\n",
    "**Pruebe diferentes configuraciones de capas y neuronas ocultas**\n",
    "\n",
    "**Pruebe o modificar otros parámetros de la red neuronal**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#hidden_layer_sizes uno es el numero de capas y otro el numero de neuronas en cada capa\n",
    "\n",
    "model_RN = MLPClassifier(solver='lbfgs',alpha=1e-5,\n",
    "                         hidden_layer_sizes=(3, 3), random_state =1)\n",
    "\n",
    "#train the model \n",
    "model_RN.fit(X_train, y_train)\n",
    "\n",
    "#predict outputs\n",
    "y_hat_RN = model_RN.predict(X_test)\n",
    "\n",
    "#accuracy\n",
    "acc = np.mean(y_hat_RN == y_test)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
